{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "%session_id_prefix native-iceberg-dataframe-\n%glue_version 3.0\n%idle_timeout 60\n%%configure \n{\n  \"--conf\": \"spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n  \"--datalake-formats\": \"iceberg\",\n  \"--JOB_NAME\": \"cdc_full_iceberg\"\n}",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "Setting session ID prefix to native-iceberg-dataframe-\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 476466d6-1a93-45d7-9f13-4b9d8e1879e3.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Setting Glue version to: 3.0\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 476466d6-1a93-45d7-9f13-4b9d8e1879e3.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Current idle_timeout is 60 minutes.\nidle_timeout has been set to 60 minutes.\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 476466d6-1a93-45d7-9f13-4b9d8e1879e3.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "The following configurations have been updated: {'--conf': 'spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions', '--datalake-formats': 'iceberg', '--JOB_NAME': 'cdc_full_iceberg'}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "catalog_name = \"glue_catalog\"\nbucket_name = \"chiholee-datalake001\"\ndatabase_name = \"ecommerce\"\n\ntable_name = \"product\"\nlast_update_time = 'last_update_time'\n\nsource_bucket_prefix = \"transaction/initial/raw\"\nsource_path = f\"s3://{bucket_name}/{source_bucket_prefix}\"\nsource_table_name = table_name\n\niceberg_bucket_prefix = \"transaction/iceberg/glue\"\nwarehouse_path = f\"s3://{bucket_name}/{iceberg_bucket_prefix}\"\niceberg_table_name = f\"{table_name}_cdc_glue_iceberg\"\n\n\n\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 117,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n    .config(f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n    .config(f\"spark.sql.catalog.{catalog_name}.warehouse\", f\"{warehouse_path}\") \\\n    .config(f\"spark.sql.catalog.{catalog_name}.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\") \\\n    .config(f\"spark.sql.catalog.{catalog_name}.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n    .config(\"spark.sql.extensions\",\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n    .getOrCreate()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 118,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import sys\nfrom awsglue.context import GlueContext\nfrom awsglue.utils import getResolvedOptions\nfrom awsglue.job import Job\n\n\nglueContext = GlueContext(spark)\n\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\njob = Job(glueContext)\njob.init(args['JOB_NAME'], args)\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 119,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(f'{source_path}/{database_name}/{source_table_name}/')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 120,
			"outputs": [
				{
					"name": "stdout",
					"text": "s3://chiholee-datalake001/transaction/initial/raw/ecommerce/product/\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDyf = glueContext.create_dynamic_frame_from_options(\n    connection_type='s3',\n    connection_options={\n        'paths': [f'{source_path}/{database_name}/{source_table_name}/'],\n        'groupFiles': 'none',\n        'recurse': True\n    },\n    format='parquet',\n    transformation_ctx='fullDyf')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 121,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(f\"Count of data after last job bookmark:{fullDyf.count()}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 122,
			"outputs": [
				{
					"name": "stdout",
					"text": "Count of data after last job bookmark:20\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDf = fullDyf.toDF()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 123,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDf.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 124,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------+--------+-----------+--------+-----+-------------------+\n|product_id|    name|   img_path|category|price|   last_update_time|\n+----------+--------+-----------+--------+-----+-------------------+\n|        15|  고추장|img/15.jpeg|    반찬|12000|2023-04-10 14:24:21|\n|        11|      쌀|img/11.jpeg|  농산물|35000|2023-04-10 14:23:58|\n|        13|  비빔밥|img/13.jpeg|    분식| 9000|2023-04-10 14:24:15|\n|        10|  핫도그| img/10.jpg|    분식| 1600|2023-04-07 14:54:42|\n|         5|  삼계탕| img/05.jpg|    육류|15000|2023-04-07 14:52:19|\n|        14|  깍뚜기|img/14.jpeg|    반찬|10000|2023-04-10 14:24:38|\n|        12|    두부|img/12.jpeg|    반찬| 3500|2023-04-10 14:24:08|\n|        19|  계란찜|img/19.jpeg|    반찬| 7000|2023-04-10 14:24:52|\n|         6|  발효빵| img/03.jpg|      빵| 7000|2023-04-07 14:53:04|\n|         4|  삼겹살| img/04.jpg|    육류|11000|2023-04-07 14:51:55|\n|         7|  고추전| img/07.jpg|    분식|11000|2023-04-07 14:53:31|\n|         2|    김치| img/01.jpg|    반찬| 8000|2023-04-07 03:11:09|\n|        16|    게장|img/16.jpeg|    반찬|20000|2023-04-10 14:24:27|\n|         3|  떡볶이| img/02.jpg|    분식| 4000|2023-04-07 03:22:07|\n|         1|새우튀김| img/06.jpg|    분식| 2000|2023-04-07 03:06:17|\n|        20|  짜장면|img/20.jpeg|    분식| 8500|2023-04-10 14:25:33|\n|         9|    치킨| img/09.jpg|    육류|18000|2023-04-07 14:54:28|\n|         8|    족발| img/08.jpg|    안주|18000|2023-04-07 14:53:59|\n|        17|  된장국|img/17.jpeg|  된장국| 8000|2023-04-10 14:24:31|\n|        18|    호박|img/18.jpeg|    채소|12000|2023-04-10 14:24:35|\n+----------+--------+-----------+--------+-----+-------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from datetime import datetime\nfrom pyspark.sql.functions import year, month, dayofmonth\nfrom pyspark.sql.functions import concat, col, lit, to_timestamp\n\ncurrent_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\nfullDf = fullDf.withColumn(last_update_time,to_timestamp(col(last_update_time)))\nfullDf = (fullDf\n      .withColumn('year', year(col(last_update_time)))\n      .withColumn('month', month(col(last_update_time)))\n      .withColumn('day', dayofmonth(col(last_update_time)))\n     )\nfullDf = fullDf.withColumn('last_applied_date',to_timestamp(lit(current_datetime)))\n\n\n\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 125,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Incoming records violate the writer assumption that records are clustered by spec and by partition within each spec. Either cluster the incoming records or switch to fanout writers.\n# 아래 insert select 시 위의 에러가 발생하여 파티션 & 정렬함\nfullDf = fullDf.repartition(\"year\", \"month\", \"day\").sortWithinPartitions(\"year\", \"month\", \"day\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 126,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDf.createOrReplaceTempView(f\"{source_table_name}_initial\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 127,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDf.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 128,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------+--------+-----------+--------+-----+-------------------+----+-----+---+-------------------+\n|product_id|    name|   img_path|category|price|   last_update_time|year|month|day|  last_applied_date|\n+----------+--------+-----------+--------+-----+-------------------+----+-----+---+-------------------+\n|         5|  삼계탕| img/05.jpg|    육류|15000|2023-04-07 14:52:19|2023|    4|  7|2024-04-30 02:25:34|\n|         7|  고추전| img/07.jpg|    분식|11000|2023-04-07 14:53:31|2023|    4|  7|2024-04-30 02:25:34|\n|         3|  떡볶이| img/02.jpg|    분식| 4000|2023-04-07 03:22:07|2023|    4|  7|2024-04-30 02:25:34|\n|         9|    치킨| img/09.jpg|    육류|18000|2023-04-07 14:54:28|2023|    4|  7|2024-04-30 02:25:34|\n|        10|  핫도그| img/10.jpg|    분식| 1600|2023-04-07 14:54:42|2023|    4|  7|2024-04-30 02:25:34|\n|         8|    족발| img/08.jpg|    안주|18000|2023-04-07 14:53:59|2023|    4|  7|2024-04-30 02:25:34|\n|         6|  발효빵| img/03.jpg|      빵| 7000|2023-04-07 14:53:04|2023|    4|  7|2024-04-30 02:25:34|\n|         4|  삼겹살| img/04.jpg|    육류|11000|2023-04-07 14:51:55|2023|    4|  7|2024-04-30 02:25:34|\n|         2|    김치| img/01.jpg|    반찬| 8000|2023-04-07 03:11:09|2023|    4|  7|2024-04-30 02:25:34|\n|         1|새우튀김| img/06.jpg|    분식| 2000|2023-04-07 03:06:17|2023|    4|  7|2024-04-30 02:25:34|\n|        19|  계란찜|img/19.jpeg|    반찬| 7000|2023-04-10 14:24:52|2023|    4| 10|2024-04-30 02:25:34|\n|        18|    호박|img/18.jpeg|    채소|12000|2023-04-10 14:24:35|2023|    4| 10|2024-04-30 02:25:34|\n|        15|  고추장|img/15.jpeg|    반찬|12000|2023-04-10 14:24:21|2023|    4| 10|2024-04-30 02:25:34|\n|        11|      쌀|img/11.jpeg|  농산물|35000|2023-04-10 14:23:58|2023|    4| 10|2024-04-30 02:25:34|\n|        13|  비빔밥|img/13.jpeg|    분식| 9000|2023-04-10 14:24:15|2023|    4| 10|2024-04-30 02:25:34|\n|        17|  된장국|img/17.jpeg|  된장국| 8000|2023-04-10 14:24:31|2023|    4| 10|2024-04-30 02:25:34|\n|        12|    두부|img/12.jpeg|    반찬| 3500|2023-04-10 14:24:08|2023|    4| 10|2024-04-30 02:25:34|\n|        16|    게장|img/16.jpeg|    반찬|20000|2023-04-10 14:24:27|2023|    4| 10|2024-04-30 02:25:34|\n|        20|  짜장면|img/20.jpeg|    분식| 8500|2023-04-10 14:25:33|2023|    4| 10|2024-04-30 02:25:34|\n|        14|  깍뚜기|img/14.jpeg|    반찬|10000|2023-04-10 14:24:38|2023|    4| 10|2024-04-30 02:25:34|\n+----------+--------+-----------+--------+-----+-------------------+----+-----+---+-------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {catalog_name}.{database_name}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 129,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "existing_tables = spark.sql(f\"SHOW TABLES IN {catalog_name}.{database_name};\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 130,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_existing_tables = existing_tables.select('tableName').rdd.flatMap(lambda x:x).collect()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 131,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.sql(f\"\"\"DROP TABLE {catalog_name}.{database_name}.{iceberg_table_name}\"\"\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 132,
			"outputs": [
				{
					"name": "stdout",
					"text": "AnalysisException: Table or view not found for 'DROP TABLE': glue_catalog.ecommerce.product_cdc_glue_iceberg; line 1 pos 0;\n'DropTable false, false\n+- 'UnresolvedTableOrView [glue_catalog, ecommerce, product_cdc_glue_iceberg], DROP TABLE, true\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS {catalog_name}.{database_name}.{iceberg_table_name}\n            USING iceberg \n            PARTITIONED BY (year, month, day)\n            as (SELECT * from {source_table_name}_initial)\"\"\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 133,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}