{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T01:21:06.657962Z",
     "iopub.status.busy": "2024-05-01T01:21:06.657647Z",
     "iopub.status.idle": "2024-05-01T01:21:06.678933Z",
     "shell.execute_reply": "2024-05-01T01:21:06.678186Z",
     "shell.execute_reply.started": "2024-05-01T01:21:06.657922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.extensions': 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions', 'spark.sql.catalog.glue_catalog': 'org.apache.iceberg.spark.SparkCatalog', 'spark.sql.catalog.glue_catalog.warehouse': 's3://chiholee-datalake001/transaction/iceberg/emr', 'spark.sql.catalog.glue_catalog.catalog-impl': 'org.apache.iceberg.aws.glue.GlueCatalog', 'spark.sql.catalog.glue_catalog.io-impl': 'org.apache.iceberg.aws.s3.S3FileIO', 'spark.sql.catalog.glue_catalog.lock-impl': 'org.apache.iceberg.aws.dynamodb.DynamoDbLockManager', 'spark.sql.catalog.glue_catalog.lock.table': 'myGlueLockTable'}, 'proxyUser': 'user_admin', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:11:12.318570Z",
     "iopub.status.busy": "2024-05-01T03:11:12.318268Z",
     "iopub.status.idle": "2024-05-01T03:11:12.890597Z",
     "shell.execute_reply": "2024-05-01T03:11:12.889825Z",
     "shell.execute_reply.started": "2024-05-01T03:11:12.318542Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.extensions': 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions', 'spark.sql.catalog.glue_catalog': 'org.apache.iceberg.spark.SparkCatalog', 'spark.sql.catalog.glue_catalog.warehouse': 's3://chiholee-datalake001/transaction/iceberg/emr', 'spark.sql.catalog.glue_catalog.catalog-impl': 'org.apache.iceberg.aws.glue.GlueCatalog', 'spark.sql.catalog.glue_catalog.io-impl': 'org.apache.iceberg.aws.s3.S3FileIO', 'spark.sql.catalog.glue_catalog.lock-impl': 'org.apache.iceberg.aws.dynamodb.DynamoDbLockManager', 'spark.sql.catalog.glue_catalog.lock.table': 'myGlueLockTable'}, 'proxyUser': 'user_admin', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "\"conf\":{\n",
    "    \"spark.sql.extensions\":\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    \"spark.sql.catalog.glue_catalog\":\"org.apache.iceberg.spark.SparkCatalog\",\n",
    "    \"spark.sql.catalog.glue_catalog.warehouse\":\"s3://chiholee-datalake001/transaction/iceberg/emr\",\n",
    "    \"spark.sql.catalog.glue_catalog.catalog-impl\":\"org.apache.iceberg.aws.glue.GlueCatalog\",\n",
    "    \"spark.sql.catalog.glue_catalog.io-impl\":\"org.apache.iceberg.aws.s3.S3FileIO\",\n",
    "    \"spark.sql.catalog.glue_catalog.lock-impl\":\"org.apache.iceberg.aws.dynamodb.DynamoDbLockManager\",\n",
    "    \"spark.sql.catalog.glue_catalog.lock.table\":\"myGlueLockTable\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:50:44.298538Z",
     "iopub.status.busy": "2024-05-01T03:50:44.298314Z",
     "iopub.status.idle": "2024-05-01T03:50:44.366798Z",
     "shell.execute_reply": "2024-05-01T03:50:44.362605Z",
     "shell.execute_reply.started": "2024-05-01T03:50:44.298516Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2e3a74647c4c6ca841add8bdf63839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "catalog_name = \"glue_catalog\"\n",
    "bucket_name = \"chiholee-datalake001\"\n",
    "database_name = \"ecommerce\"\n",
    "\n",
    "table_name = \"orders\"\n",
    "pk = 'order_id'\n",
    "last_update_time = 'order_dt'\n",
    "\n",
    "source_bucket_prefix = \"transaction/cdc/raw\"\n",
    "source_path = f\"s3://{bucket_name}/{source_bucket_prefix}\"\n",
    "source_table_name = table_name\n",
    "\n",
    "iceberg_bucket_prefix = \"transaction/iceberg/emr\"\n",
    "warehouse_path = f\"s3://{bucket_name}/{iceberg_bucket_prefix}\"\n",
    "iceberg_table_name = f\"{table_name}_cdc_emr_iceberg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:12:08.481775Z",
     "iopub.status.busy": "2024-05-01T03:12:08.481532Z",
     "iopub.status.idle": "2024-05-01T03:12:08.570445Z",
     "shell.execute_reply": "2024-05-01T03:12:08.569705Z",
     "shell.execute_reply.started": "2024-05-01T03:12:08.481751Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c43b03806064fbab80b23b3fbf9e833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://chiholee-datalake001/transaction/iceberg/emr"
     ]
    }
   ],
   "source": [
    "print(f\"{warehouse_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T01:25:09.402686Z",
     "iopub.status.busy": "2024-05-01T01:25:09.402467Z",
     "iopub.status.idle": "2024-05-01T01:25:09.458892Z",
     "shell.execute_reply": "2024-05-01T01:25:09.458289Z",
     "shell.execute_reply.started": "2024-05-01T01:25:09.402663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a2f89e28db4f3a826fa96774ed99dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder \\\n",
    "#     .config(f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "#     .config(f\"spark.sql.catalog.{catalog_name}.warehouse\", f\"{warehouse_path}\") \\\n",
    "#     .config(f\"spark.sql.catalog.{catalog_name}.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\") \\\n",
    "#     .config(f\"spark.sql.catalog.{catalog_name}.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
    "#     .config(\"spark.sql.extensions\",\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "#     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T01:25:12.671203Z",
     "iopub.status.busy": "2024-05-01T01:25:12.670959Z",
     "iopub.status.idle": "2024-05-01T01:25:27.997086Z",
     "shell.execute_reply": "2024-05-01T01:25:27.996353Z",
     "shell.execute_reply.started": "2024-05-01T01:25:12.671176Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce04a08e1e8416c99bd9b71195f9f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.33.13-py3-none-any.whl (139 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3) (1.0.1)\n",
      "Collecting botocore<1.34.0,>=1.33.13\n",
      "  Downloading botocore-1.33.13-py3-none-any.whl (11.8 MB)\n",
      "Collecting s3transfer<0.9.0,>=0.8.2\n",
      "  Downloading s3transfer-0.8.2-py3-none-any.whl (82 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4; python_version < \"3.10\"\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.13->boto3) (1.13.0)\n",
      "Installing collected packages: urllib3, python-dateutil, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.33.13 botocore-1.33.13 python-dateutil-2.9.0.post0 s3transfer-0.8.2 urllib3-1.26.18\n",
      "\n",
      "WARNING: The directory '/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag."
     ]
    }
   ],
   "source": [
    "# sc.install_pypi_package(\"boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:12:15.626158Z",
     "iopub.status.busy": "2024-05-01T03:12:15.625928Z",
     "iopub.status.idle": "2024-05-01T03:12:15.893619Z",
     "shell.execute_reply": "2024-05-01T03:12:15.892957Z",
     "shell.execute_reply.started": "2024-05-01T03:12:15.626134Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81221a0c974a437ab743ea9fccca5925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:12:21.116807Z",
     "iopub.status.busy": "2024-05-01T03:12:21.116588Z",
     "iopub.status.idle": "2024-05-01T03:12:21.381591Z",
     "shell.execute_reply": "2024-05-01T03:12:21.380843Z",
     "shell.execute_reply.started": "2024-05-01T03:12:21.116784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ae130a38014da78846b5c5383ad8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)"
     ]
    }
   ],
   "source": [
    "dynamodb = boto3.resource('dynamodb', region_name=\"ap-northeast-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:12:23.950845Z",
     "iopub.status.busy": "2024-05-01T03:12:23.950617Z",
     "iopub.status.idle": "2024-05-01T03:12:24.011748Z",
     "shell.execute_reply": "2024-05-01T03:12:24.011160Z",
     "shell.execute_reply.started": "2024-05-01T03:12:23.950821Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47544069ec8d41638918ae0b2a18bd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_table(dynamodb):\n",
    "    try:\n",
    "        table = dynamodb.create_table(\n",
    "            TableName='ProcessedFiles',\n",
    "            KeySchema=[\n",
    "                {\n",
    "                    'AttributeName': 'Id',  # 고정 파티션 키\n",
    "                    'KeyType': 'HASH'\n",
    "                }\n",
    "            ],\n",
    "            AttributeDefinitions=[\n",
    "                {\n",
    "                    'AttributeName': 'Id',\n",
    "                    'AttributeType': 'S'\n",
    "                }\n",
    "                # ProcessedDate는 여기서 정의할 필요 없음\n",
    "            ],\n",
    "            ProvisionedThroughput={\n",
    "                'ReadCapacityUnits': 1,\n",
    "                'WriteCapacityUnits': 1\n",
    "            }\n",
    "        )\n",
    "        # 테이블 생성 대기\n",
    "        table.wait_until_exists()\n",
    "        print(\"Table created successfully.\")\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'ResourceInUseException':\n",
    "            print(\"Table already exists.\")\n",
    "        else:\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:12:25.047563Z",
     "iopub.status.busy": "2024-05-01T03:12:25.047334Z",
     "iopub.status.idle": "2024-05-01T03:12:25.316878Z",
     "shell.execute_reply": "2024-05-01T03:12:25.316242Z",
     "shell.execute_reply.started": "2024-05-01T03:12:25.047540Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c52651c0dd643ffb989d053d3e23bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "try:\n",
    "    table = dynamodb.Table('ProcessedFiles')\n",
    "    table.load()\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "        create_table(dynamodb)\n",
    "        table = dynamodb.Table('ProcessedFiles')\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:52:27.145554Z",
     "iopub.status.busy": "2024-05-01T03:52:27.145315Z",
     "iopub.status.idle": "2024-05-01T03:52:27.201713Z",
     "shell.execute_reply": "2024-05-01T03:52:27.200948Z",
     "shell.execute_reply.started": "2024-05-01T03:52:27.145529Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ed4fea553647bd80501e5dedb278d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_last_processed_info(table):\n",
    "    try:\n",
    "        response = table.get_item(\n",
    "            Key={'Id': 'LastProcessedInfo'}\n",
    "        )\n",
    "        if 'Item' in response:\n",
    "            # 파일 이름과 처리 날짜 둘 다 반환\n",
    "            last_processed_date = datetime.strptime(response['Item']['LastProcessedDate'], '%Y-%m-%dT%H:%M:%S')\n",
    "            return last_processed_date\n",
    "        else:\n",
    "            print(\"No last processed info found.\")\n",
    "            return None\n",
    "    except ClientError as e:\n",
    "        print(f\"Failed to fetch last processed info: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_last_processed_info(table, start_date, last_processed_date):\n",
    "    try:\n",
    "        # DynamoDB 항목 업데이트\n",
    "        response = table.update_item(\n",
    "            Key={\n",
    "                'Id': 'LastProcessedInfo'  # 변경: 'LastProcessedDate' -> 'LastProcessedInfo'\n",
    "            },\n",
    "            UpdateExpression=\"SET StartDate = :startdate, LastProcessedDate = :lastprocesseddate\",\n",
    "            ExpressionAttributeValues={\n",
    "                ':startdate': start_date.isoformat(),\n",
    "                ':lastprocesseddate': last_processed_date.isoformat()\n",
    "            },\n",
    "            ReturnValues=\"UPDATED_NEW\"\n",
    "        )\n",
    "        print(\"Update succeeded:\", response)\n",
    "    except ClientError as e:\n",
    "        print(f\"Failed to update last processed info: {e}\")\n",
    "        \n",
    "        \n",
    "def generate_date_paths(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    end_date = end_date.replace(hour=23, minute=59, second=59, microsecond=0)\n",
    "    while current_date <= end_date:\n",
    "        yield f\"{source_path}/{database_name}/{source_table_name}/{current_date.strftime('%Y/%m/%d/')}\"\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:52:27.778360Z",
     "iopub.status.busy": "2024-05-01T03:52:27.778139Z",
     "iopub.status.idle": "2024-05-01T03:52:27.828855Z",
     "shell.execute_reply": "2024-05-01T03:52:27.828285Z",
     "shell.execute_reply.started": "2024-05-01T03:52:27.778337Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda5b92c52b84e018661c21ad070ce88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_processed_date = get_last_processed_info(table)\n",
    "start_date = datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:53:27.707795Z",
     "iopub.status.busy": "2024-05-01T03:53:27.707460Z",
     "iopub.status.idle": "2024-05-01T03:53:27.769755Z",
     "shell.execute_reply": "2024-05-01T03:53:27.768806Z",
     "shell.execute_reply.started": "2024-05-01T03:53:27.707753Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c1b3d1a1bd42dbbdca4b2e47eca5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-01 03:43:35"
     ]
    }
   ],
   "source": [
    "print(last_processed_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:53:30.039115Z",
     "iopub.status.busy": "2024-05-01T03:53:30.038771Z",
     "iopub.status.idle": "2024-05-01T03:53:30.109357Z",
     "shell.execute_reply": "2024-05-01T03:53:30.108528Z",
     "shell.execute_reply.started": "2024-05-01T03:53:30.039077Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92fefebb0654ffe99d2f14454109321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "if last_processed_date:\n",
    "#     paths = list(generate_date_paths(last_processed_date + timedelta(days=1), today))\n",
    "    paths = list(generate_date_paths(last_processed_date, start_date))\n",
    "else:\n",
    "    # 마지막 처리 날짜 정보가 없을 경우, 고정 기간을 설정하거나 전체 데이터를 재처리\n",
    "    paths = list(generate_date_paths(start_date - timedelta(days=30), start_date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:53:31.184772Z",
     "iopub.status.busy": "2024-05-01T03:53:31.184553Z",
     "iopub.status.idle": "2024-05-01T03:53:31.240106Z",
     "shell.execute_reply": "2024-05-01T03:53:31.239527Z",
     "shell.execute_reply.started": "2024-05-01T03:53:31.184749Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3356ce710040d08c6dd0479cf15698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/05/01/']"
     ]
    }
   ],
   "source": [
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:12:31.533049Z",
     "iopub.status.busy": "2024-05-01T03:12:31.532832Z",
     "iopub.status.idle": "2024-05-01T03:12:31.591728Z",
     "shell.execute_reply": "2024-05-01T03:12:31.591044Z",
     "shell.execute_reply.started": "2024-05-01T03:12:31.533026Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a181e0353924308ac3f9b2059acde61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = spark.read.parquet(\"s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/30/20240430-000106420.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:12:32.385678Z",
     "iopub.status.busy": "2024-05-01T03:12:32.385453Z",
     "iopub.status.idle": "2024-05-01T03:12:32.440863Z",
     "shell.execute_reply": "2024-05-01T03:12:32.440303Z",
     "shell.execute_reply.started": "2024-05-01T03:12:32.385654Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbed783a6d604dcb9f4d1ee6594f3c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:12:33.103150Z",
     "iopub.status.busy": "2024-05-01T03:12:33.102921Z",
     "iopub.status.idle": "2024-05-01T03:12:33.163813Z",
     "shell.execute_reply": "2024-05-01T03:12:33.163220Z",
     "shell.execute_reply.started": "2024-05-01T03:12:33.103126Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e60dfb280c54dcc9ce5c53d2a85975e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamodb.Table(name='ProcessedFiles')"
     ]
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:12:33.783237Z",
     "iopub.status.busy": "2024-05-01T03:12:33.782991Z",
     "iopub.status.idle": "2024-05-01T03:13:05.200135Z",
     "shell.execute_reply": "2024-05-01T03:13:05.199542Z",
     "shell.execute_reply.started": "2024-05-01T03:12:33.783213Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02f7a9b13bd42268771d82e230d870d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/01/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/01.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/02/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/02.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/03/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/03.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/04/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/04.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/05/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/05.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/06/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/06.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/07/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/07.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/08/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/08.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/09/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/09.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/10/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/10.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/11/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/11.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/12/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/12.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/13/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/13.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/14/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/14.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/15/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/15.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/16/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/16.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/17/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/17.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/18/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/18.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/19/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/19.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/20/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/20.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/21/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/21.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/22/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/22.\n",
      "Error reading data from s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/23/: [PATH_NOT_FOUND] Path does not exist: s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/23."
     ]
    }
   ],
   "source": [
    "# paths = ['s3://chiholee-datalake001/transaction/cdc/raw/ecommerce/orders/2024/04/30/']\n",
    "\n",
    "merged_df = None\n",
    "\n",
    "for path in paths:\n",
    "    try:\n",
    "        df = spark.read.option(\"basePath\", f'{source_path}/{database_name}/{source_table_name}/').parquet(path)\n",
    "        if df.rdd.isEmpty():\n",
    "            print(f\"No data found at {path}\")\n",
    "        else:\n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "                last_processed_file = path  # 첫 번째로 데이터가 있는 파일을 기록\n",
    "            else:\n",
    "                merged_df = merged_df.union(df)\n",
    "            last_processed_file = path  # 최신 파일 경로를 업데이트\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data from {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:13:05.201346Z",
     "iopub.status.busy": "2024-05-01T03:13:05.201154Z",
     "iopub.status.idle": "2024-05-01T03:13:05.261043Z",
     "shell.execute_reply": "2024-05-01T03:13:05.260460Z",
     "shell.execute_reply.started": "2024-05-01T03:13:05.201315Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b50dfc729a44b06aadec59569571aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# merged_df.show()\n",
    "# last_processed_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:13:05.262565Z",
     "iopub.status.busy": "2024-05-01T03:13:05.262385Z",
     "iopub.status.idle": "2024-05-01T03:13:05.323678Z",
     "shell.execute_reply": "2024-05-01T03:13:05.322810Z",
     "shell.execute_reply.started": "2024-05-01T03:13:05.262542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbc26a557254308a46612874c2a9187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if merged_df:\n",
    "#     merged_df.show()  # 병합된 데이터셋 출력\n",
    "#     update_last_processed_date(table, start_date, last_processed_date)  # DynamoDB에 마지막으로 처리된 날짜 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:13:05.325402Z",
     "iopub.status.busy": "2024-05-01T03:13:05.325151Z",
     "iopub.status.idle": "2024-05-01T03:13:05.391170Z",
     "shell.execute_reply": "2024-05-01T03:13:05.390293Z",
     "shell.execute_reply.started": "2024-05-01T03:13:05.325368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f54cedf81542f09d657b29be115419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None"
     ]
    }
   ],
   "source": [
    "print(last_processed_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:13:05.392731Z",
     "iopub.status.busy": "2024-05-01T03:13:05.392489Z",
     "iopub.status.idle": "2024-05-01T03:13:05.661178Z",
     "shell.execute_reply": "2024-05-01T03:13:05.660546Z",
     "shell.execute_reply.started": "2024-05-01T03:13:05.392696Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25c254ec55541cfa122498c7db1e447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df.createOrReplaceTempView(\"cdcDf\")\n",
    "\n",
    "# 쿼리 작성 로직 조정\n",
    "if last_processed_date is not None:\n",
    "    # last_processed_date를 datetime 객체로 변환 (이미 datetime 형태일 수 있음)\n",
    "    if isinstance(last_processed_date, str):\n",
    "        last_processed_date = datetime.strptime(last_processed_date, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    # last_processed_date에서 1분을 빼기\n",
    "    time_threshold = last_processed_date - timedelta(minutes=1)\n",
    "    # 날짜 조건이 있는 쿼리\n",
    "    query = f\"\"\"\n",
    "    select *\n",
    "    from cdcDf\n",
    "    where (order_id, order_dt) in\n",
    "    (\n",
    "        select order_id, max(order_dt) max_op_time\n",
    "        from cdcDf\n",
    "        WHERE order_dt > '{time_threshold.strftime('%Y-%m-%d %H:%M:%S')}'\n",
    "        group by order_id\n",
    "    )\n",
    "    \"\"\"\n",
    "else:\n",
    "    # 날짜 조건이 없는 쿼리\n",
    "    query = \"\"\"\n",
    "    select *\n",
    "    from cdcDf\n",
    "    where (order_id, order_dt) in\n",
    "    (\n",
    "        select order_id, max(order_dt) max_op_time\n",
    "        from cdcDf\n",
    "        group by order_id\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:13:05.662635Z",
     "iopub.status.busy": "2024-05-01T03:13:05.662236Z",
     "iopub.status.idle": "2024-05-01T03:13:05.939431Z",
     "shell.execute_reply": "2024-05-01T03:13:05.938829Z",
     "shell.execute_reply.started": "2024-05-01T03:13:05.662580Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b518be19c5f2406d9f52c8fcef3de8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cdcDf = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:13:05.940543Z",
     "iopub.status.busy": "2024-05-01T03:13:05.940352Z",
     "iopub.status.idle": "2024-05-01T03:14:39.572101Z",
     "shell.execute_reply": "2024-05-01T03:14:39.571362Z",
     "shell.execute_reply.started": "2024-05-01T03:13:05.940521Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c728f7dbe61b4bf18fc68ead92ff8f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted count: 286836\n",
      "Updated count: 31849\n",
      "Deleted count: 0\n",
      "Total CDC count: 318685"
     ]
    }
   ],
   "source": [
    "cdcInsertCount = cdcDf.filter(\"Op = 'I'\").count()\n",
    "cdcUpdateCount = cdcDf.filter(\"Op = 'U'\").count()\n",
    "cdcDeleteCount = cdcDf.filter(\"Op = 'D'\").count()\n",
    "print(f\"Inserted count: {cdcInsertCount}\")\n",
    "print(f\"Updated count: {cdcUpdateCount}\")\n",
    "print(f\"Deleted count: {cdcDeleteCount}\")\n",
    "print(f\"Total CDC count: {cdcDf.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:14:39.573945Z",
     "iopub.status.busy": "2024-05-01T03:14:39.573744Z",
     "iopub.status.idle": "2024-05-01T03:14:39.637543Z",
     "shell.execute_reply": "2024-05-01T03:14:39.636890Z",
     "shell.execute_reply.started": "2024-05-01T03:14:39.573920Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c495c0d0f8774b22b8dede8f7ea3b87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropColumnList = ['Op','dms_update_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:14:39.638765Z",
     "iopub.status.busy": "2024-05-01T03:14:39.638595Z",
     "iopub.status.idle": "2024-05-01T03:14:39.898800Z",
     "shell.execute_reply": "2024-05-01T03:14:39.897813Z",
     "shell.execute_reply.started": "2024-05-01T03:14:39.638743Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342969ee22c04e04b2033d2003c8f361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "from pyspark.sql.functions import concat, col, lit, to_timestamp\n",
    "\n",
    "current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "cdcDf = cdcDf.withColumn('order_dt',to_timestamp(col('order_dt')))\n",
    "cdcDf = (cdcDf\n",
    "      .withColumn('year', year(col('order_dt')))\n",
    "      .withColumn('month', month(col('order_dt')))\n",
    "      .withColumn('day', dayofmonth(col('order_dt')))\n",
    "     )\n",
    "cdcDf = cdcDf.withColumn('last_applied_date',to_timestamp(lit(current_datetime)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:14:39.900606Z",
     "iopub.status.busy": "2024-05-01T03:14:39.900093Z",
     "iopub.status.idle": "2024-05-01T03:14:49.214056Z",
     "shell.execute_reply": "2024-05-01T03:14:49.213380Z",
     "shell.execute_reply.started": "2024-05-01T03:14:39.900567Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fb308da04949a3908a35b1011a970e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {catalog_name}.{database_name}\")\n",
    "# existing_tables = spark.sql(f\"SHOW TABLES IN {catalog_name}.{database_name};\")\n",
    "# df_existing_tables = existing_tables.select('tableName').rdd.flatMap(lambda x:x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:14:49.215134Z",
     "iopub.status.busy": "2024-05-01T03:14:49.214971Z",
     "iopub.status.idle": "2024-05-01T03:14:49.478458Z",
     "shell.execute_reply": "2024-05-01T03:14:49.477808Z",
     "shell.execute_reply.started": "2024-05-01T03:14:49.215114Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed53c4f10674eacad9d3077f9ea0fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upsertDf = cdcDf.filter(\"Op != 'D'\").drop(*dropColumnList)\n",
    "upsertDf.createOrReplaceTempView(f\"{source_table_name}_upsert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:19:33.724397Z",
     "iopub.status.busy": "2024-05-01T03:19:33.724161Z",
     "iopub.status.idle": "2024-05-01T03:19:39.014578Z",
     "shell.execute_reply": "2024-05-01T03:19:39.013818Z",
     "shell.execute_reply.started": "2024-05-01T03:19:33.724372Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73de4c1e57d4b609ee676e4d25d4837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|order_id|count(1)|\n",
      "+--------+--------+\n",
      "+--------+--------+"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "select order_id, count(*)\n",
    "from {catalog_name}.{database_name}.{iceberg_table_name}\n",
    "group by order_id\n",
    "having count(*) > 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-01T03:20:16.073783Z",
     "iopub.status.busy": "2024-05-01T03:20:16.073558Z",
     "iopub.status.idle": "2024-05-01T03:21:23.595197Z",
     "shell.execute_reply": "2024-05-01T03:21:23.594458Z",
     "shell.execute_reply.started": "2024-05-01T03:20:16.073759Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39b92e75c72444f85a80a3fc797c718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "An error occurred while calling o94.sql.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Authorized committer (attemptNumber=0, stage=94, partition=11) failed; but task commit success, data duplication may happen. reason=ExceptionFailure(java.io.UncheckedIOException,Failed to create output stream for location: s3://chiholee-datalake001/transaction/iceberg/emr/ecommerce.db/orders_cdc_emr_iceberg/data/year=2024/month=4/day=27/00011-5729-f7bc2aa8-0240-4c45-ad21-4809f2e98cd8-00001.parquet,[Ljava.lang.StackTraceElement;@18e913b9,java.io.UncheckedIOException: Failed to create output stream for location: s3://chiholee-datalake001/transaction/iceberg/emr/ecommerce.db/orders_cdc_emr_iceberg/data/year=2024/month=4/day=27/00011-5729-f7bc2aa8-0240-4c45-ad21-4809f2e98cd8-00001.parquet\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputFile.createOrOverwrite(S3OutputFile.java:72)\n",
      "\tat org.apache.iceberg.parquet.ParquetIO$ParquetOutputFile.createOrOverwrite(ParquetIO.java:151)\n",
      "\tat org.apache.iceberg.shaded.org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:345)\n",
      "\tat org.apache.iceberg.shaded.org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:323)\n",
      "\tat org.apache.iceberg.parquet.ParquetWriter.ensureWriterInitialized(ParquetWriter.java:111)\n",
      "\tat org.apache.iceberg.parquet.ParquetWriter.flushRowGroup(ParquetWriter.java:210)\n",
      "\tat org.apache.iceberg.parquet.ParquetWriter.close(ParquetWriter.java:254)\n",
      "\tat org.apache.iceberg.io.DataWriter.close(DataWriter.java:82)\n",
      "\tat org.apache.iceberg.io.RollingFileWriter.closeCurrentWriter(RollingFileWriter.java:122)\n",
      "\tat org.apache.iceberg.io.RollingFileWriter.close(RollingFileWriter.java:147)\n",
      "\tat org.apache.iceberg.io.RollingDataWriter.close(RollingDataWriter.java:32)\n",
      "\tat org.apache.iceberg.io.ClusteredWriter.closeCurrentWriter(ClusteredWriter.java:118)\n",
      "\tat org.apache.iceberg.io.ClusteredWriter.close(ClusteredWriter.java:110)\n",
      "\tat org.apache.iceberg.io.ClusteredDataWriter.close(ClusteredDataWriter.java:31)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$PartitionedDataWriter.close(SparkWrite.java:783)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$PartitionedDataWriter.commit(SparkWrite.java:765)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.$anonfun$run$1(WriteToDataSourceV2Exec.scala:482)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1575)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:509)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:448)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:514)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:411)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:563)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1541)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:566)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.io.IOException: Failed to create staging directory due to some unknown reason: /mnt3/yarn/usercache/livy/appcache/application_1714532057255_0003/container_1714532057255_0003_01_000001/tmp\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputStream.createStagingDirectoryIfNotExists(S3OutputStream.java:502)\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputStream.newStream(S3OutputStream.java:231)\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputStream.<init>(S3OutputStream.java:150)\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputFile.createOrOverwrite(S3OutputFile.java:70)\n",
      "\t... 30 more\n",
      ",Some(org.apache.spark.ThrowableSerializationWrapper@7b8fd94d),Vector(AccumulableInfo(15419,None,Some(1081),None,false,true,None), AccumulableInfo(15421,None,Some(0),None,false,true,None), AccumulableInfo(15426,None,Some(69140480),None,false,true,None), AccumulableInfo(15428,None,Some(17),None,false,true,None), AccumulableInfo(15429,None,Some(9),None,false,true,None), AccumulableInfo(15430,None,Some(983122),None,false,true,None), AccumulableInfo(15431,None,Some(0),None,false,true,None), AccumulableInfo(15432,None,Some(539799),None,false,true,None), AccumulableInfo(15433,None,Some(0),None,false,true,None), AccumulableInfo(15434,None,Some(48877),None,false,true,None), AccumulableInfo(15435,None,Some(0),None,false,true,None), AccumulableInfo(15436,None,Some(0),None,false,true,None), AccumulableInfo(15437,None,Some(0),None,false,true,None), AccumulableInfo(15438,None,Some(0),None,false,true,None), AccumulableInfo(15439,None,Some(0),None,false,true,None), AccumulableInfo(15440,None,Some(0),None,false,true,None), AccumulableInfo(15441,None,Some(0),None,false,true,None), AccumulableInfo(15442,None,Some(0),None,false,true,None), AccumulableInfo(15443,None,Some(5),None,false,true,None), AccumulableInfo(15444,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 15419, name: Some(internal.metrics.executorRunTime), value: 1081), LongAccumulator(id: 15421, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 15426, name: Some(internal.metrics.peakExecutionMemory), value: 69140480), LongAccumulator(id: 15428, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 17), LongAccumulator(id: 15429, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 9), LongAccumulator(id: 15430, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 983122), LongAccumulator(id: 15431, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 15432, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 539799), LongAccumulator(id: 15433, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 15434, name: Some(internal.metrics.shuffle.read.recordsRead), value: 48877), LongAccumulator(id: 15435, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 15436, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 15437, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 15438, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 15439, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 15440, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 15441, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 15442, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 15443, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 5), LongAccumulator(id: 15444, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2974)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2910)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2909)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2909)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleStageFailed$1(DAGScheduler.scala:1256)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleStageFailed$1$adapted(DAGScheduler.scala:1256)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleStageFailed(DAGScheduler.scala:1256)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3170)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3112)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3101)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1028)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2271)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:408)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:382)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.ReplaceDataExec.writeWithV2(ReplaceDataExec.scala:29)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run(WriteToDataSourceV2Exec.scala:360)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.ReplaceDataExec.run(ReplaceDataExec.scala:29)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:250)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:123)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$9(SQLExecution.scala:160)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:250)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$8(SQLExecution.scala:160)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:271)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:159)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:69)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:101)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:554)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:107)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:554)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:530)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:97)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:82)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:221)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:101)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:98)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:640)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:630)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:662)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt3/yarn/usercache/livy/appcache/application_1714532057255_0003/container_1714532057255_0003_01_000001/pyspark.zip/pyspark/sql/session.py\", line 1440, in sql\n",
      "    return DataFrame(self._jsparkSession.sql(sqlQuery, litArgs), self)\n",
      "  File \"/mnt3/yarn/usercache/livy/appcache/application_1714532057255_0003/container_1714532057255_0003_01_000001/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1323, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/mnt3/yarn/usercache/livy/appcache/application_1714532057255_0003/container_1714532057255_0003_01_000001/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 169, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/mnt3/yarn/usercache/livy/appcache/application_1714532057255_0003/container_1714532057255_0003_01_000001/py4j-0.10.9.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o94.sql.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Authorized committer (attemptNumber=0, stage=94, partition=11) failed; but task commit success, data duplication may happen. reason=ExceptionFailure(java.io.UncheckedIOException,Failed to create output stream for location: s3://chiholee-datalake001/transaction/iceberg/emr/ecommerce.db/orders_cdc_emr_iceberg/data/year=2024/month=4/day=27/00011-5729-f7bc2aa8-0240-4c45-ad21-4809f2e98cd8-00001.parquet,[Ljava.lang.StackTraceElement;@18e913b9,java.io.UncheckedIOException: Failed to create output stream for location: s3://chiholee-datalake001/transaction/iceberg/emr/ecommerce.db/orders_cdc_emr_iceberg/data/year=2024/month=4/day=27/00011-5729-f7bc2aa8-0240-4c45-ad21-4809f2e98cd8-00001.parquet\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputFile.createOrOverwrite(S3OutputFile.java:72)\n",
      "\tat org.apache.iceberg.parquet.ParquetIO$ParquetOutputFile.createOrOverwrite(ParquetIO.java:151)\n",
      "\tat org.apache.iceberg.shaded.org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:345)\n",
      "\tat org.apache.iceberg.shaded.org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:323)\n",
      "\tat org.apache.iceberg.parquet.ParquetWriter.ensureWriterInitialized(ParquetWriter.java:111)\n",
      "\tat org.apache.iceberg.parquet.ParquetWriter.flushRowGroup(ParquetWriter.java:210)\n",
      "\tat org.apache.iceberg.parquet.ParquetWriter.close(ParquetWriter.java:254)\n",
      "\tat org.apache.iceberg.io.DataWriter.close(DataWriter.java:82)\n",
      "\tat org.apache.iceberg.io.RollingFileWriter.closeCurrentWriter(RollingFileWriter.java:122)\n",
      "\tat org.apache.iceberg.io.RollingFileWriter.close(RollingFileWriter.java:147)\n",
      "\tat org.apache.iceberg.io.RollingDataWriter.close(RollingDataWriter.java:32)\n",
      "\tat org.apache.iceberg.io.ClusteredWriter.closeCurrentWriter(ClusteredWriter.java:118)\n",
      "\tat org.apache.iceberg.io.ClusteredWriter.close(ClusteredWriter.java:110)\n",
      "\tat org.apache.iceberg.io.ClusteredDataWriter.close(ClusteredDataWriter.java:31)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$PartitionedDataWriter.close(SparkWrite.java:783)\n",
      "\tat org.apache.iceberg.spark.source.SparkWrite$PartitionedDataWriter.commit(SparkWrite.java:765)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.$anonfun$run$1(WriteToDataSourceV2Exec.scala:482)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1575)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:509)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:448)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:514)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:411)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:563)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1541)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:566)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.io.IOException: Failed to create staging directory due to some unknown reason: /mnt3/yarn/usercache/livy/appcache/application_1714532057255_0003/container_1714532057255_0003_01_000001/tmp\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputStream.createStagingDirectoryIfNotExists(S3OutputStream.java:502)\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputStream.newStream(S3OutputStream.java:231)\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputStream.<init>(S3OutputStream.java:150)\n",
      "\tat org.apache.iceberg.aws.s3.S3OutputFile.createOrOverwrite(S3OutputFile.java:70)\n",
      "\t... 30 more\n",
      ",Some(org.apache.spark.ThrowableSerializationWrapper@7b8fd94d),Vector(AccumulableInfo(15419,None,Some(1081),None,false,true,None), AccumulableInfo(15421,None,Some(0),None,false,true,None), AccumulableInfo(15426,None,Some(69140480),None,false,true,None), AccumulableInfo(15428,None,Some(17),None,false,true,None), AccumulableInfo(15429,None,Some(9),None,false,true,None), AccumulableInfo(15430,None,Some(983122),None,false,true,None), AccumulableInfo(15431,None,Some(0),None,false,true,None), AccumulableInfo(15432,None,Some(539799),None,false,true,None), AccumulableInfo(15433,None,Some(0),None,false,true,None), AccumulableInfo(15434,None,Some(48877),None,false,true,None), AccumulableInfo(15435,None,Some(0),None,false,true,None), AccumulableInfo(15436,None,Some(0),None,false,true,None), AccumulableInfo(15437,None,Some(0),None,false,true,None), AccumulableInfo(15438,None,Some(0),None,false,true,None), AccumulableInfo(15439,None,Some(0),None,false,true,None), AccumulableInfo(15440,None,Some(0),None,false,true,None), AccumulableInfo(15441,None,Some(0),None,false,true,None), AccumulableInfo(15442,None,Some(0),None,false,true,None), AccumulableInfo(15443,None,Some(5),None,false,true,None), AccumulableInfo(15444,None,Some(0),None,false,true,None)),Vector(LongAccumulator(id: 15419, name: Some(internal.metrics.executorRunTime), value: 1081), LongAccumulator(id: 15421, name: Some(internal.metrics.resultSize), value: 0), LongAccumulator(id: 15426, name: Some(internal.metrics.peakExecutionMemory), value: 69140480), LongAccumulator(id: 15428, name: Some(internal.metrics.shuffle.read.remoteBlocksFetched), value: 17), LongAccumulator(id: 15429, name: Some(internal.metrics.shuffle.read.localBlocksFetched), value: 9), LongAccumulator(id: 15430, name: Some(internal.metrics.shuffle.read.remoteBytesRead), value: 983122), LongAccumulator(id: 15431, name: Some(internal.metrics.shuffle.read.remoteBytesReadToDisk), value: 0), LongAccumulator(id: 15432, name: Some(internal.metrics.shuffle.read.localBytesRead), value: 539799), LongAccumulator(id: 15433, name: Some(internal.metrics.shuffle.read.fetchWaitTime), value: 0), LongAccumulator(id: 15434, name: Some(internal.metrics.shuffle.read.recordsRead), value: 48877), LongAccumulator(id: 15435, name: Some(internal.metrics.shuffle.push.read.corruptMergedBlockChunks), value: 0), LongAccumulator(id: 15436, name: Some(internal.metrics.shuffle.push.read.mergedFetchFallbackCount), value: 0), LongAccumulator(id: 15437, name: Some(internal.metrics.shuffle.push.read.remoteMergedBlocksFetched), value: 0), LongAccumulator(id: 15438, name: Some(internal.metrics.shuffle.push.read.localMergedBlocksFetched), value: 0), LongAccumulator(id: 15439, name: Some(internal.metrics.shuffle.push.read.remoteMergedChunksFetched), value: 0), LongAccumulator(id: 15440, name: Some(internal.metrics.shuffle.push.read.localMergedChunksFetched), value: 0), LongAccumulator(id: 15441, name: Some(internal.metrics.shuffle.push.read.remoteMergedBytesRead), value: 0), LongAccumulator(id: 15442, name: Some(internal.metrics.shuffle.push.read.localMergedBytesRead), value: 0), LongAccumulator(id: 15443, name: Some(internal.metrics.shuffle.read.remoteReqsDuration), value: 5), LongAccumulator(id: 15444, name: Some(internal.metrics.shuffle.push.read.remoteMergedReqsDuration), value: 0)),WrappedArray(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2974)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2910)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2909)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2909)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleStageFailed$1(DAGScheduler.scala:1256)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleStageFailed$1$adapted(DAGScheduler.scala:1256)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleStageFailed(DAGScheduler.scala:1256)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3170)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3112)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3101)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1028)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2271)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:408)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:382)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.ReplaceDataExec.writeWithV2(ReplaceDataExec.scala:29)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run(WriteToDataSourceV2Exec.scala:360)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run$(WriteToDataSourceV2Exec.scala:359)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.ReplaceDataExec.run(ReplaceDataExec.scala:29)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:250)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:123)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$9(SQLExecution.scala:160)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:107)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:250)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$8(SQLExecution.scala:160)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:271)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:159)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:69)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:101)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:97)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:554)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:107)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:554)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:530)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:97)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:82)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:221)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:101)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:98)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:640)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:630)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:662)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Table {source_table_name}_iceberg is upserting...\")\n",
    "spark.sql(f\"\"\"MERGE INTO {catalog_name}.{database_name}.{iceberg_table_name} t\n",
    "    USING {source_table_name}_upsert s ON s.{pk} = t.{pk}\n",
    "    WHEN MATCHED THEN UPDATE SET *\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:33:32.389015Z",
     "iopub.status.busy": "2024-05-01T03:33:32.388764Z",
     "iopub.status.idle": "2024-05-01T03:34:01.762912Z",
     "shell.execute_reply": "2024-05-01T03:34:01.762003Z",
     "shell.execute_reply.started": "2024-05-01T03:33:32.388989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5423becd3947c18af1d2dac3e474bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+-----------+-------------------+-----------+----------+----+-----+---+-------------------+\n",
      "|order_id|promo_id|order_cnt|order_price|           order_dt|customer_id|product_id|year|month|day|  last_applied_date|\n",
      "+--------+--------+---------+-----------+-------------------+-----------+----------+----+-----+---+-------------------+\n",
      "|  290165| PROMO03|        8|       9000|2024-04-24 15:28:52|         60|         4|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  134566| PROMO19|        7|      14000|2024-04-24 15:28:55|         89|         3|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290166| PROMO10|        6|      34000|2024-04-24 15:28:56|         81|        18|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290167| PROMO14|        9|      44000|2024-04-24 15:28:57|         49|         3|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290168| PROMO12|       10|      13000|2024-04-24 15:28:57|         99|        13|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290169| PROMO13|        5|      12000|2024-04-24 15:28:58|         60|         9|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|   83054| PROMO07|       10|      47000|2024-04-24 15:29:01|         47|         5|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290170| PROMO13|        1|      32000|2024-04-24 15:29:04|         11|         9|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|   13246| PROMO01|        8|      34000|2024-04-24 15:29:07|         54|        20|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290173| PROMO20|        2|       8000|2024-04-24 15:29:10|         33|         1|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290174| PROMO15|        2|      50000|2024-04-24 15:29:10|         39|         7|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290175| PROMO13|        5|      49000|2024-04-24 15:29:13|         64|         6|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290176| PROMO19|        4|      11000|2024-04-24 15:29:14|          7|         4|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290177| PROMO13|        3|      18000|2024-04-24 15:29:14|         97|         3|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290178| PROMO03|       10|      32000|2024-04-24 15:29:15|          6|         4|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290179| PROMO01|        6|      18000|2024-04-24 15:29:18|         49|        11|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290180| PROMO12|        6|      24000|2024-04-24 15:29:19|         45|        10|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290182| PROMO11|       10|       7000|2024-04-24 15:29:23|         69|        14|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290183| PROMO20|        3|      50000|2024-04-24 15:29:24|         26|         4|2024|    4| 24|2024-05-01 03:14:39|\n",
      "|  290184| PROMO09|        3|      12000|2024-04-24 15:29:24|          1|         4|2024|    4| 24|2024-05-01 03:14:39|\n",
      "+--------+--------+---------+-----------+-------------------+-----------+----------+----+-----+---+-------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "upsertDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:34:06.938471Z",
     "iopub.status.busy": "2024-05-01T03:34:06.938253Z",
     "iopub.status.idle": "2024-05-01T03:34:34.290127Z",
     "shell.execute_reply": "2024-05-01T03:34:34.289502Z",
     "shell.execute_reply.started": "2024-05-01T03:34:06.938448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de6783837144a3d9503cff2c628693a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_order_dt = upsertDf.agg({\"order_dt\": \"max\"}).collect()[0][\"max(order_dt)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T03:34:34.291410Z",
     "iopub.status.busy": "2024-05-01T03:34:34.291226Z",
     "iopub.status.idle": "2024-05-01T03:34:34.354634Z",
     "shell.execute_reply": "2024-05-01T03:34:34.353997Z",
     "shell.execute_reply.started": "2024-05-01T03:34:34.291388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac596670aba94b14a53c730655a11d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-01 03:12:11"
     ]
    }
   ],
   "source": [
    "print(max_order_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_last_processed_date(table, start_date, max_order_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
