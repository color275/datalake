{
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "%session_id_prefix orders_cdc_full_iceberg_01\n%glue_version 3.0\n%idle_timeout 60\n%%configure \n{\n  \"--conf\": \"spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n  \"--datalake-formats\": \"iceberg\",\n  \"--JOB_NAME\": \"orders_cdc_full_iceberg\"\n}",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "Setting session ID prefix to orders_cdc_full_iceberg_01\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 476466d6-1a93-45d7-9f13-4b9d8e1879e3.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Setting Glue version to: 3.0\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 476466d6-1a93-45d7-9f13-4b9d8e1879e3.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Current idle_timeout is 60 minutes.\nidle_timeout has been set to 60 minutes.\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 476466d6-1a93-45d7-9f13-4b9d8e1879e3.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "The following configurations have been updated: {'--conf': 'spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions', '--datalake-formats': 'iceberg', '--JOB_NAME': 'orders_cdc_full_iceberg'}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "catalog_name = \"glue_catalog\"\nbucket_name = \"chiholee-datalake001\"\ndatabase_name = \"ecommerce\"\n\ntable_name = \"orders\"\nlast_update_time = 'order_dt'\n\nsource_bucket_prefix = \"transaction/initial/raw\"\nsource_path = f\"s3://{bucket_name}/{source_bucket_prefix}\"\nsource_table_name = table_name\n\niceberg_bucket_prefix = \"transaction/iceberg/glue\"\nwarehouse_path = f\"s3://{bucket_name}/{iceberg_bucket_prefix}\"\niceberg_table_name = f\"{table_name}_cdc_glue_iceberg\"\n\n\n\n",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 53,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n    .config(f\"spark.sql.catalog.{catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n    .config(f\"spark.sql.catalog.{catalog_name}.warehouse\", f\"{warehouse_path}\") \\\n    .config(f\"spark.sql.catalog.{catalog_name}.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\") \\\n    .config(f\"spark.sql.catalog.{catalog_name}.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n    .config(\"spark.sql.extensions\",\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n    .getOrCreate()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 54,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# GLUE NOTEBOOK SAVE 상태에서 진행\nimport sys\nfrom awsglue.job import Job\nfrom awsglue.context import GlueContext\nfrom awsglue.utils import getResolvedOptions\n\n\nglueContext = GlueContext(spark)\n\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\njob = Job(glueContext)\njob.init(args['JOB_NAME'], args)\n",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 55,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(f'{source_path}/{database_name}/{source_table_name}/')",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 56,
			"outputs": [
				{
					"name": "stdout",
					"text": "s3://chiholee-datalake001/transaction/initial/raw/ecommerce/orders/\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDyf = glueContext.create_dynamic_frame_from_options(\n    connection_type='s3',\n    connection_options={\n        'paths': [f'{source_path}/{database_name}/{source_table_name}/'],\n        'groupFiles': 'none',\n        'recurse': True\n    },\n    format='parquet',\n    transformation_ctx='fullDyf')",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 57,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(f\"Count of data after last job bookmark:{fullDyf.count()}\")",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 58,
			"outputs": [
				{
					"name": "stdout",
					"text": "Count of data after last job bookmark:288650\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDf = fullDyf.toDF()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 59,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDf.show()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 60,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+--------+---------+-----------+-------------------+-----------+----------+\n|order_id|promo_id|order_cnt|order_price|           order_dt|customer_id|product_id|\n+--------+--------+---------+-----------+-------------------+-----------+----------+\n|  192041| PROMO02|        8|      31000|2024-04-22 06:32:25|         70|         6|\n|  249635| PROMO20|        7|      45000|2024-04-23 12:47:36|         22|        10|\n|  199096| PROMO20|        9|      19000|2024-04-22 10:14:55|         85|         8|\n|  281230| PROMO08|        8|      25000|2024-04-24 05:15:36|         96|         1|\n|  252318| PROMO20|        3|      31000|2024-04-23 14:11:15|         30|        14|\n|  212103| PROMO09|       10|      39000|2024-04-22 17:05:54|         35|         1|\n|  256471| PROMO10|        1|      14000|2024-04-23 16:21:21|         36|        14|\n|  218664| PROMO16|        1|      47000|2024-04-22 20:34:47|         10|         1|\n|  244040| PROMO12|        1|       9000|2024-04-23 09:51:51|         45|         4|\n|  267307| PROMO13|       10|      33000|2024-04-23 21:59:27|         22|         6|\n|  277880| PROMO03|        4|      38000|2024-04-24 03:31:24|         71|         4|\n|  261905| PROMO14|        4|      41000|2024-04-23 19:12:18|         29|         7|\n|  214577| PROMO13|        8|      31000|2024-04-22 18:24:20|         99|        15|\n|  221670| PROMO09|        5|      50000|2024-04-22 22:07:11|         61|         7|\n|  217521| PROMO04|        5|      23000|2024-04-22 19:58:19|          3|        13|\n|  280276| PROMO18|        2|      17000|2024-04-24 04:44:53|         22|        12|\n|  203801| PROMO06|        5|      25000|2024-04-22 12:44:47|         51|         2|\n|  270519| PROMO18|       10|      42000|2024-04-23 23:39:31|         51|         8|\n|  206924| PROMO10|        7|      40000|2024-04-22 14:23:54|          4|        15|\n|  210235| PROMO06|        4|      17000|2024-04-22 16:06:20|         28|        15|\n+--------+--------+---------+-----------+-------------------+-----------+----------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from datetime import datetime\nfrom pyspark.sql.functions import year, month, dayofmonth\nfrom pyspark.sql.functions import concat, col, lit, to_timestamp\n\ncurrent_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\nfullDf = fullDf.withColumn(last_update_time,to_timestamp(col(last_update_time)))\nfullDf = (fullDf\n      .withColumn('year', year(col(last_update_time)))\n      .withColumn('month', month(col(last_update_time)))\n      .withColumn('day', dayofmonth(col(last_update_time)))\n     )\nfullDf = fullDf.withColumn('last_applied_date',to_timestamp(lit(current_datetime)))\n\n\n\n",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 61,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Incoming records violate the writer assumption that records are clustered by spec and by partition within each spec. Either cluster the incoming records or switch to fanout writers.\n# 아래 insert select 시 위의 에러가 발생하여 파티션 & 정렬함\nfullDf = fullDf.repartition(\"year\", \"month\", \"day\").sortWithinPartitions(\"year\", \"month\", \"day\")",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 62,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDf.createOrReplaceTempView(f\"{source_table_name}_initial\")",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 63,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullDf.show()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 64,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+--------+---------+-----------+-------------------+-----------+----------+----+-----+---+-------------------+\n|order_id|promo_id|order_cnt|order_price|           order_dt|customer_id|product_id|year|month|day|  last_applied_date|\n+--------+--------+---------+-----------+-------------------+-----------+----------+----+-----+---+-------------------+\n|  172376| PROMO10|        8|      35000|2024-04-24 02:40:10|         90|         4|2024|    4| 24|2024-04-30 02:19:37|\n|  181420| PROMO11|        4|       9000|2024-04-24 07:05:54|         28|         2|2024|    4| 24|2024-04-30 02:19:37|\n|  186901| PROMO05|        9|       9000|2024-04-24 04:19:56|         75|        15|2024|    4| 24|2024-04-30 02:19:37|\n|  129025| PROMO19|        1|      42000|2024-04-24 01:20:38|          7|         4|2024|    4| 24|2024-04-30 02:19:37|\n|  118004| PROMO06|        4|      38000|2024-04-24 03:09:38|         38|        16|2024|    4| 24|2024-04-30 02:19:37|\n|  148775| PROMO03|        3|       6000|2024-04-24 01:11:46|         98|        13|2024|    4| 24|2024-04-30 02:19:37|\n|  114728| PROMO06|        1|      36000|2024-04-24 01:18:06|         87|         3|2024|    4| 24|2024-04-30 02:19:37|\n|  123539| PROMO13|        4|      25000|2024-04-24 07:27:05|         35|        15|2024|    4| 24|2024-04-30 02:19:37|\n|  184005| PROMO03|        5|       5000|2024-04-24 03:38:49|         36|         9|2024|    4| 24|2024-04-30 02:19:37|\n|  186665| PROMO09|        3|      38000|2024-04-24 07:26:55|         11|        14|2024|    4| 24|2024-04-30 02:19:37|\n|  162462| PROMO03|        3|      43000|2024-04-24 06:27:44|         69|         3|2024|    4| 24|2024-04-30 02:19:37|\n|  164494| PROMO10|        8|      39000|2024-04-24 05:18:36|         12|        17|2024|    4| 24|2024-04-30 02:19:37|\n|  117434| PROMO09|       10|      16000|2024-04-24 00:46:57|          9|         7|2024|    4| 24|2024-04-30 02:19:37|\n|  162444| PROMO16|       10|      13000|2024-04-24 04:23:44|         12|         1|2024|    4| 24|2024-04-30 02:19:37|\n|  115106| PROMO14|        3|      21000|2024-04-24 01:09:03|         97|        16|2024|    4| 24|2024-04-30 02:19:37|\n|  176365| PROMO20|        9|       9000|2024-04-24 00:41:28|         80|         4|2024|    4| 24|2024-04-30 02:19:37|\n|  168941| PROMO12|        1|      31000|2024-04-24 00:16:37|         32|        19|2024|    4| 24|2024-04-30 02:19:37|\n|  172670| PROMO09|        5|      39000|2024-04-24 03:51:00|         88|        17|2024|    4| 24|2024-04-30 02:19:37|\n|  155505| PROMO08|        2|      40000|2024-04-24 03:24:02|         91|        11|2024|    4| 24|2024-04-30 02:19:37|\n|  169198| PROMO05|        5|       9000|2024-04-24 14:05:05|         59|        10|2024|    4| 24|2024-04-30 02:19:37|\n+--------+--------+---------+-----------+-------------------+-----------+----------+----+-----+---+-------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {catalog_name}.{database_name}\")",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 65,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "existing_tables = spark.sql(f\"SHOW TABLES IN {catalog_name}.{database_name};\")",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 66,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_existing_tables = existing_tables.select('tableName').rdd.flatMap(lambda x:x).collect()",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 67,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# spark.sql(f\"\"\"DROP TABLE {catalog_name}.{database_name}.{iceberg_table_name}\"\"\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 52,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.sql(f\"\"\"CREATE TABLE IF NOT EXISTS {catalog_name}.{database_name}.{iceberg_table_name}\n            USING iceberg \n            PARTITIONED BY (year, month, day)\n            as (SELECT * from {source_table_name}_initial)\"\"\")",
			"metadata": {
				"trusted": true,
				"tags": [],
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": 68,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"execution_count": null,
			"outputs": []
		}
	]
}